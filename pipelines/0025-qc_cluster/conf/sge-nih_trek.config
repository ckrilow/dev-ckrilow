// Configuration for Sun Grid Engine (SGE) workload management platform

executor {
    name = 'sge'

    // Set perJobMemLimit to true. See:
    // * https://github.com/nextflow-io/nextflow/issues/123
    // * https://gitter.im/nextflow-io/nextflow/archives/2018/02/09
    perJobMemLimit = true
} // end executor

process {
    executor = 'sge'

    // BASE SETTINGS START
    // error strategy
    errorStrategy = 'retry'
    maxRetries = 2

    // basic resources
    memory = 15.GB
    //time = { 20.m * task.attempt }
    // basic output settings
    publish_mode = "copy" // symlink or copy
    // BASE SETTINGS END

    // sge users will need to edit the below parameters to fit their platform
    //queue = 'normal'
    queueSize = 1000
    killBatchSize = 1000

    // native configuration options
    clusterOptions = { "-l h_vmem="+task.memory.toMega()+"M" }
    //clusterOptions = { "-R \"span[hosts=1]\"" }

    // specific settings for processes with specific labels such as
    // big_mem, short, long
    //withLabel: big_mem {
    //    cpus = 16
    //    memory = 64.GB
    //    queue = 'hugemem'
    //}
    withLabel: gpu {
        //queue = 'gpu_testing'
        // need to use trek non-standard queue
        clusterOptions = { "-l h_vmem="+task.memory.toMega()+"M,gpu=1 -P 'gpu_testing'" }
    }

    // BASE SETTINGS START
    // process-specific resources
    withName: run_scrublet {
        memory = { 25.GB * task.attempt }
    }
    withName: make_cellmetadata_pipeline_input {
        memory = { 5.GB * task.attempt }
    }
    withName: merge_samples {
        memory = { 20.GB * task.attempt }
    }
    withName: normalize_and_pca {
        // cpus = 8
        memory = { (50.GB / 8) * task.attempt }
        clusterOptions = { "-l h_vmem="+task.memory.toMega()+"M -pe make-dedicated 8" }
    }
    withName: subset_pcs {
        memory = { 5.GB * task.attempt }
    }
    withName: harmony {
        memory = { 20.GB * task.attempt }
    }
    withName: bbknn {
        // cpus = 4
        memory = { (20.GB / 4) * task.attempt }
        clusterOptions = { "-l h_vmem="+task.memory.toMega()+"M -pe make-dedicated 4" }
    }
    withName: cluster {
        //cpus = 4
        memory = { (20.GB / 4) * task.attempt }
        clusterOptions = { "-l h_vmem="+task.memory.toMega()+"M -pe make-dedicated 4" }
    }
    withName: cluster_validate_resolution_sklearn {
        // cpus = { 8 * task.attempt }
        memory = { (40.GB / 8 * task.attempt) * task.attempt }
        clusterOptions = { "-l h_vmem="+task.memory.toMega()+"M -pe make-dedicated "+ 8 * task.attempt }
    }
    // Tensorflow wants to use all available memory on a GPU, so make sure we
    // request lots of memory. Most nodes have 754.5G on Sanger farm, so
    // request ~1/2.
    withName: cluster_validate_resolution_keras {
        memory = 370.GB
        //memory = 150.GB
    }
    withName: plot_resolution_validate {
        memory = { 80.GB * task.attempt }
    }
    withName: cluster_markers {
        //cpus = 4
        memory = { (15.GB / 4) * task.attempt }
        clusterOptions = { "-l h_vmem="+task.memory.toMega()+"M -pe make-dedicated 4" }
    }
    withName: merge_clusters {
        // cpus = 8
        memory = { (30.GB / 8) * task.attempt }
        clusterOptions = { "-l h_vmem="+task.memory.toMega()+"M -pe make-dedicated 8" }
    }
    withName: convert_seurat {
        memory = { 60.GB * task.attempt }
    }
    withName: umap_calculate {
        // cpus = 8
        memory = { (50.GB / 8) * task.attempt }
        clusterOptions = { "-l h_vmem="+task.memory.toMega()+"M -pe make-dedicated 8" }
    }
    withName: umap_gather {
        memory = { 400.GB * task.attempt }
    }

    withName: umap_plot_swarm {
	memory = { 50.GB * task.attempt }
    }

    withName: umap_calculate_and_plot {
        // cpus = 8
        memory = { (50.GB / 8) * task.attempt }
        clusterOptions = { "-l h_vmem="+task.memory.toMega()+"M -pe make-dedicated 8" }
    }
    
    withName: plot_phenotype_across_clusters {
	memory = { 30.GB * task.attempt }
    }
    // BASE SETTINGS END

} // end process

timeline {
    enabled = true
}
